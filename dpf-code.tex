\documentclass[11pt]{article}

\usepackage{adb}

\newcommand{\mybox}{%
    \collectbox{%
        \setlength{\fboxsep}{4pt}%
        \fbox{\BOXCONTENT}%
    }%
}

\oddsidemargin0cm
\topmargin-2cm     %I recommend adding these three lines to increase the 
\textwidth16.5cm   %amount of usable space on the page (and save trees)
\textheight23.5cm  
\newcommand{\question}[1] {\vspace{.3in} \hrule\vspace{0.3em}
\noindent{\bf #1} \vspace{0.7em}
\hrule \vspace{.10in}}
\renewcommand{\part}[1] {\vspace{.10in} {\bf (#1)}}

\newcommand{\myinfo}{Albert Gao / sixiangg}
\newcommand{\myhwnum}{1}
\newcommand{\currdate}{02/27/2022}

\newcommand{\Gen}{\textsf{Gen}}
\newcommand{\Eval}{\textsf{Eval}}
\newcommand{\Rec}{\textsf{Rec}}
\newcommand{\Sim}{\textsf{Sim}}
\newcommand{\Real}{\textsf{Real}}
\newcommand{\Ideal}{\textsf{Ideal}}

\setlength{\parindent}{0pt}
\setlength{\parskip}{5pt plus 1pt}
 
%\pagestyle{fancyplain}
%\lhead{\fancyplain{}{\textbf{HW\myhwnum}}}      % Note the different brackets!
%\rhead{\fancyplain{}{\bigskip\myinfo}}
%\chead{\fancyplain{}{21-623}}

\begin{document}

\bigskip                        % Skip a "medium" amount of space
                                % (latex determines what medium is)
                                % Also try: \bigskip, \littleskip

\thispagestyle{plain}
\begin{center}                  % Center the following lines
{\Huge Coded DPF Proofs}

\vspace{0.3cm}

\large{\myinfo}

\large{\currdate}

\end{center}

\section{Context}
We explore the problem of retrieving an item from a server without revealing which item is retrieved. This general class of problems is generally referred to as private information retrieval (PIR), first introduced in~\cite{chor95}. One class of approaches to this problem makes use of distributed point functions (DPF), first introduced in~\cite{gi14}, with improvements in~\cite{bgi15} and~\cite{bgi18}. Another direction to the problem of PIR is the storage model of servers. Instead of assuming multiple servers that replicate the same data set, some recent work such as~\cite{tajeddine19} looks at PIR involving servers with coded storage. We show that the DPF technique can be applied to the coded setting while maintaining polylogarithmic communication complexity.

Before adapting our approach to coded storage, we first discuss DPF in the setting of replicated storage as well as some of its extensions. Roughly speaking, suppose a client desires item index $\alpha \in \{0,1\}^m$; each server $j \in [n]$ has access to two functions $h,g_j : \{0,1\}^m \to \{0,1\}^r$ such that $h(\gamma)$ is the data at index $\gamma$ and $f = \sum_j g_j$ is a coordinate function that vanishes everwhere but $\alpha$, where $f(\alpha) = 1$. Then as long as each $g_j$ by itself does not reveal $\alpha$ and servers cannot collude, we can compute $h(\alpha) = (h \cdot f)(\alpha) = \sum_\alpha h(\alpha) \sum_j g_j(\alpha) = \sum_j \sum_\alpha h(\alpha)g_j(\alpha)$, where each server $j$ only communicates $\sum_\alpha h(\alpha)g_j(\alpha)$ to the client. We now make our notion precise.
\begin{definition}
(Point Function). For $m,r \in \mathbb{Z}^+, \alpha \in \{0,1\}^m, \mu \in \{0,1\}^r$, the point function $f_{\alpha, \mu} : \{0,1\}^m \to \{0,1\}^r$ is defined via
\begin{align*}
  f_{\alpha, \mu}(\beta) = \begin{cases}
  \mu, &\beta = \alpha\\
  0^r, &\beta \neq \alpha
  \end{cases}.
\end{align*}
\end{definition}
In order to share point functions among $n$ servers, the client generates $n$ relatively short keys so the servers can evaluate each of the shared functions without too much trouble. Here, we assume one-way functions exist, which implies pseudorandom generators (PRGs) exist.
\begin{definition}
(Distributed Point Function: Syntax). An $n$-party distributed point function (DPF) is a tuple of algorithms (\Gen, \Eval, \Rec) with the following syntax.
\begin{itemize}
  \item \Gen($1^\lambda, \alpha, \mu$) is a PPT algorithm that outputs $n$ keys $(k_1, \cdots, k_n)$, where $1^\lambda$ is the security parameter, $\alpha \in \{0,1\}^m$, and $\mu \in \{0,1\}^r$.
  \item \Eval($k, \beta$) is a PPT algorithm that outputs some $\kappa \in \{0,1\}^r$, where $\beta \in \{0,1\}^m$.
  \item \Rec($\{(i, \kappa_i) : i \in [n]\}$) is a PPT algorithm that outputs some $\mu' \in \{0,1\}^r$.
\end{itemize}
\end{definition}
DPF under the setting of at most $a$ unresponsive failures (or $b$ Byzantine servers) is where $\Eval$ may instead return empty string (or arbitrary strings) for at most $a$ (or $b$) servers. We now specify what it means for a DPF to be secure.
\begin{definition}
(Distributed Point Function: Security). An $n$-party $t$-secure DPF is a tuple of algorithms $(\Gen, \Eval, \Rec)$ with the following properties.
\begin{itemize}
\item \textbf{Correctness:} For any nonempty $\alpha, \mu \in \{0,1\}^{*}$, if $(k_1, \cdots, k_n) \leftarrow \Gen(1^{\lambda}, \alpha, \mu)$, then for any $\beta \in \{0,1\}^{|\alpha|}$ we have $\Pr[\Rec(\{(i,\Eval(k_i, \beta)): i \in [n]\}) = f_{\alpha, \mu}(\beta)] = 1$.
\item \textbf{Secrecy:} For any set $S \subseteq [n]$ of size t, there exists a PPT algorithm $\Sim$ such that for every sequence of $(\alpha_\lambda \in \{0,1\}^\lambda, \mu_\lambda \in \{0,1\}^* \setminus \{\epsilon\})$ where $\lambda \in \mathbb{N}$, the outputs of the following experiments $\Real$ and $\Ideal$ are computationally indistinguishable.
\begin{itemize}
  \item $\Real(1^{\lambda}): (k_1, \cdots, k_n) \leftarrow \Gen(1^{\lambda}, \alpha_\lambda, \mu_\lambda)$. Output $(k_j)_{j \in S}$.
  \item $\Ideal(1^{\lambda}):$ Output $\Sim(1^{\lambda}, |\mu_\lambda|)$.
\end{itemize}
\end{itemize}
\end{definition}


\section{Multi-Party DPF}
We extend two-party DPF construction from~\cite{bgi18} to the $n$-party setting.
\begin{theorem}
An $n$-party $1$-secure DPF under the setting of at most $n-2$ unresponsive failures (or, less than $\frac{n}{2}$ Byzantine failures) exists.
\end{theorem}
\begin{proof}
The tuple of algorithms is specified in Algorithm~\ref{alg:dpf}

\begin{algorithm}
\caption{$n$-Party Distributed Point Function}\label{alg:dpf}
Suppose $G : \{0,1\}^\lambda \to \{0,1\}^{2(\lambda + n - 1)}$ is a pseudorandom generator. Notation-wise, if $b$ is a bit, we use $\overline{b}$ to denote $b \oplus 1$.
\vspace{10px}
\newline
\Gen($1^\lambda, \alpha, \mu$):
\begin{algorithmic}[1]
\State Let $\alpha_1, \cdots, \alpha_m$ be the bit decomposition of $\alpha$.
\State Sample $s_j^{(0)} \leftarrow \{0,1\}^{\lambda}$ for each $j \in [n]$.
\State Let $t_{j,0}^{(0)} = 0, t_{j,1}^{(0)} = 1$ for $j \in [n] \setminus \{1\}$.
\For{$i = 1 \text{ to } n$}
\State $s_j^0||t_{j,2}^0||\cdots||t_{j,n}^0||s_j^{1}||t_{j,2}^1||\cdots||t_{j,n}^1 \leftarrow G(s_j^{(i-1)})$, for each $j \in [n]$.
\State $CW_{s_j} \leftarrow s_j^{\overline{\alpha_0}} \oplus s_1^{\overline{\alpha_0}}$, for each $j \in [n] \setminus \{1\}$.
\State $CW_{t_j}$
\EndFor
\end{algorithmic}
\end{algorithm}


\end{proof}


\bibliographystyle{unsrt}
\bibliography{refs}

\end{document}